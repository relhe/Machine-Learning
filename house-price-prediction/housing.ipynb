{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/relhe/inf8245ae/blob/main/pratice/housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWHOPMoyw87J"
      },
      "source": [
        "# House price prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8Owd0vxeIw"
      },
      "source": [
        "# Overview\n",
        "This Jupyter Notebook provides a comprehensive approach to modeling and predicting house prices using machine learning techniques. This project aims to explore the relationships between housing features and their prices, leveraging data preprocessing, exploratory data analysis, feature engineering, and model evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc6MYhXbw87K"
      },
      "source": [
        "# Introduction\n",
        "The real estate market is a dynamic and complex landscape influenced by a myriad of factors, including location, property features, economic conditions, and buyer preferences. Accurately predicting house prices is essential for various stakeholders, including buyers, sellers, investors, and real estate agents, as it enables informed decision-making and strategic planning.\n",
        "\n",
        "This project focuses on modeling house prices using a dataset that contains various attributes related to residential properties. The primary goal is to develop a predictive model that can estimate house prices based on these features. By employing machine learning techniques, we aim to uncover the underlying relationships between property characteristics and their market values.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "* **Explore the Dataset**: Understand the structure and content of the data, identify trends, and visualize key relationships.\n",
        "* **Preprocess the Data**: Clean and prepare the dataset for analysis, addressing issues such as missing values and categorical variables.\n",
        "* **Engineer Features**: Create new variables that could enhance model performance based on insights gained during the exploratory analysis.\n",
        "* **Build and Evaluate Models**: Train several regression models, compare their performance using standard evaluation metrics, and select the best model for predictions.\n",
        "* **Make Predictions**: Apply the best-performing model to predict house prices for new or unseen data, demonstrating the model's practical applicability.\n",
        "\n",
        "By the end of this analysis, we will not only gain insights into the factors that influence house prices but also develop a robust predictive model that can be used in real-world scenarios. This notebook serves as a practical resource for anyone interested in leveraging data science techniques in the real estate domain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvdwtaLaw87L"
      },
      "source": [
        "## Setup dependencies for the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4jDJl6Pw87L",
        "outputId": "1b1edc51-c650-4c9f-cfa2-f42b2801e691"
      },
      "outputs": [],
      "source": [
        "%pip install numpy\n",
        "%pip install matplotlib\n",
        "%pip install pandas\n",
        "%pip install seaborn\n",
        "%pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc6z2A_Rw87M"
      },
      "source": [
        "## Importation\n",
        "* Import necessary library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wm6Xzgwhw87M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq4h6kgZw87M"
      },
      "source": [
        "# Data loading\n",
        "Load and understand the dataset containing various attributes of houses\n",
        "* load the dataset and display the first rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "mcAX8qNVw87M",
        "outputId": "ac0d8799-b6c6-40ec-8b4d-7a4303a09659"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv('Housing.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIa1u0Q4w87N"
      },
      "source": [
        "# Exploratory data analysis (EDA)\n",
        "Visualize and analyze the dataset to uncover patterns and insights that influence house prices.\n",
        "* visualizations: histograms, scatter plots, and correlation matrices.\n",
        "* Summary statistics and insights from the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYJPfan_w87N"
      },
      "outputs": [],
      "source": [
        "print(f\"That dataset has {df.shape[0]} rows and {df.shape[1]} columns\\n\")\n",
        "print(f\"The columns are: {df.columns.to_list()}\\n\")\n",
        "print(\"The data types of each column are:\")\n",
        "print(df.dtypes.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary statistics of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate descriptive statistics that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution, excluding NaN values.\n",
        "print(df.describe().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Keys insight from statistics\n",
        "* **Price Distribution**: The **mean** house price is **$4 766 729**, with a standard deviation of $1 870 440, indicating a wide range of prices within the dataset. The minimum price is $1 750 000, while the maximum reaches $13 300 000, suggesting variability based on features.\n",
        "\n",
        "* **Bedrooms** and **Bathrooms**: The average number of bedrooms is 2.9, while the average number of bathrooms is 1.2. This indicates that most houses tend to have at least 3 bedrooms and 1 bathrooms, which are common requirements for families.\n",
        "\n",
        "* **Area**: The average square footage is 5150 square feet, with a range from 1650 to 16200 square feet. This suggests that the dataset includes both smaller and larger homes, impacting the price significantly.\n",
        "\n",
        "* **stories** : The mean storey for house is 0.86, with suggest in average house has 1 storey.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"The numerical type columns are: {numerical_columns}\\n\")\n",
        "numerical_columns.remove('price')\n",
        "print(f\"The numerical type columns without the target column are: {numerical_columns}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting the distribution of the numerical columns\n",
        "for i in numerical_columns:\n",
        "    sns.histplot(df[i])\n",
        "    plt.title(f'Distribution of {i}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scatterplot of the house price versus area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.scatterplot(x='area', y='price', data=df)\n",
        "plt.title('Price vs Area')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Boxplots of price of the house versus features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting scatter plots for the numerical columns against the target column\n",
        "discrete_columns = numerical_columns.copy()\n",
        "discrete_columns.remove('area')\n",
        "for i in discrete_columns:\n",
        "    sns.boxplot(x=df[i], y=df['price'])\n",
        "    plt.title(f'Price vs {i}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Potential Correlations: Initial observations suggest that variables such as Square_Feet, Bedrooms, and Bathrooms may correlate positively with house prices. Further analysis (such as a correlation matrix) will be conducted to quantify these relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy0p6KvYw87N"
      },
      "source": [
        "# Data preprocessing\n",
        "Clean and prepare the dataset for analysis, addressing issues such as missing values and categorical variables.\n",
        "\n",
        "* Handling missing values.\n",
        "* Encoding categorical features.\n",
        "* Scaling and normalizing numerical features.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Missing values\n",
        "If exist, we will identify and handle missing values using the following approaches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"False if there are no missing values and True if there are missing values for each column:\")\n",
        "print(df.isnull().sum()>0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The is no missing value in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding categorical variables\n",
        "Machine learning algorithms require numerical input, so we need to convert categorical variables into numerical formats. We can use techniques like one-hot encoding or label encoding:\n",
        "* **One-Hot Encoding**: This method creates binary columns for each category in a categorical variable.\n",
        "* **Label Encoding**: Use this method for ordinal categories where there is a natural order. For example, if we had a categorical variable \"Quality\" with values like \"Low,\" \"Medium,\" and \"High,\" we could map them to numerical values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scaling numerical features\n",
        "To ensure that all numerical features contribute equally to model training, we can scale them using standardization (z-score normalization) or min-max scaling:\n",
        "\n",
        "* **Standardization**: This technique scales features to have a mean of 0 and a standard deviation of 1.\n",
        "* **Min-Max Scaling**: This method scales features to a specified range, typically [0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature engineering and feature selection\n",
        "After preprocessing, itâ€™s essential to select relevant features that will be used in the model. We can drop unnecessary columns or use methods like correlation analysis to determine which features contribute most to the target variable (house prices).\n",
        "\n",
        "Create new variables that could enhance model performance based on insights gained during the exploratory analysis.\n",
        "\n",
        "* Creating new features based on existing data.\n",
        "* Selecting relevant features for modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK2zj0RMw87N"
      },
      "source": [
        "# Model definition\n",
        "Train several regression models, compare their performance using standard evaluation metrics, and select the best model for predictions.\n",
        "\n",
        "* Splitting the dataset into training and test sets.\n",
        "* Training various regression models.\n",
        "* Evaluating models using appropriate metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRyJs0_dw87N"
      },
      "source": [
        "# Error or loss function to minimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yInTjQ-2w87N"
      },
      "source": [
        "# Model testing with test set"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
